{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%matplotlib inline\nimport shap\nimport lime\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn import preprocessing, metrics, model_selection\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder, OneHotEncoder, LabelBinarizer \nfrom sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, recall_score, precision_score, f1_score, precision_recall_curve\nfrom sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, train_test_split\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom datetime import datetime, date, timezone, timedelta\nimport seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os, gc\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nsns.set()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/titanic/train.csv')\ndf_test = pd.read_csv('/kaggle/input/titanic/test.csv')\ndisplay(df_train.info())\ndisplay(df_train.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_engineering(df):\n    # Null Value Handling\n    df[\"Age\"].fillna(df[\"Age\"].median(),inplace=True)\n    df[\"Embarked\"].fillna(df['Embarked'].mode()[0], inplace = True)\n    df = df.fillna(-1)\n    \n    # Feature Encoding\n    df[\"Sex\"] = df[\"Sex\"].map({'male':1,'female':0}).fillna(-1).astype(int)\n    df[\"Embarked\"] = df[\"Embarked\"].map({'S':0,'C':1,'Q':2}).astype(int)\n    df[\"Cabin\"] = df[\"Cabin\"].str[0].map({'T':0,'G':1,'F':2,'E':3,'D':4,'C':5,'B':6,'A':7}).fillna(-1).astype(int)\n    \n    # Binning\n    bins_age = np.linspace(0, 100, 10)\n    df[\"AgeBin\"] = np.digitize(df[\"Age\"], bins=bins_age)\n    \n    df[\"FareBin\"] = 0\n    df[\"FareBin\"][(df[\"Fare\"]>=0)&(df[\"Fare\"]<10)] = 1\n    df[\"FareBin\"][(df[\"Fare\"]>=10)&(df[\"Fare\"]<20)] = 2\n    df[\"FareBin\"][(df[\"Fare\"]>=20)&(df[\"Fare\"]<30)] = 3\n    df[\"FareBin\"][(df[\"Fare\"]>=30)&(df[\"Fare\"]<40)] = 4\n    df[\"FareBin\"][(df[\"Fare\"]>=40)&(df[\"Fare\"]<50)] = 5\n    df[\"FareBin\"][(df[\"Fare\"]>=50)&(df[\"Fare\"]<100)] = 6\n    df[\"FareBin\"][(df[\"Fare\"]>=100)] = 7\n\n    # Create New Features (Optional)\n    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n    df['Title'] = -1\n    df['Title'][df[\"Name\"].str.contains(\"Mr\")] = 0\n    df['Title'][df[\"Name\"].str.contains(\"Master\")] = 1\n    df['Title'][df[\"Name\"].str.contains(\"Miss\")] = 2\n    df['Title'][df[\"Name\"].str.contains(\"Mrs\")] = 3\n    \n    # Drop unsed columns\n    del df[\"Age\"]\n    del df[\"Fare\"]\n    del df[\"Ticket\"]\n    \n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_fe = feature_engineering(df_train)\ndf_test_fe = feature_engineering(df_test)\n\ndisplay(df_train_fe.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(df_train_fe[\"FareBin\"].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exclude_columns = [\n    'Name',\n    'Ticket',\n    'PassengerId',\n    'Survived'\n]\n\nevals_result = {}\nfeatures = [c for c in df_train_fe.columns if c not in exclude_columns]\ntarget = df_train_fe['Survived']\nprint(len(target))\n\ngc.collect()\n\nX_train, X_test, y_train, y_test = train_test_split(df_train_fe[features], target, test_size=0.2, random_state=440)\n\nparam = {   \n    'boost': 'gbdt',\n    'learning_rate': 0.008,\n    'feature_fraction':0.20,\n    'bagging_freq':1,\n    'bagging_fraction':1,\n    'max_depth': -1,\n    'num_leaves':17,\n    'lambda_l2': 0.9,\n    'lambda_l1': 0.9,\n    'max_bin':200,\n    'metric':{'auc','binary_logloss'},\n#    'metric':{'binary_logloss'},\n    'tree_learner': 'serial',\n    'objective': 'binary',\n    'verbosity': 1,\n}\n\noof = np.zeros(len(df_train_fe))\npredictions = np.zeros(len(df_test_fe))\nfeature_importance_train = pd.DataFrame()\n\nlgb_train = lgb.Dataset(X_train, y_train)\nlgb_valid = lgb.Dataset(X_test, y_test)\nnum_round = 10000\nclf = lgb.train(param, lgb_train, num_round, valid_sets = [lgb_train, lgb_valid],\n      verbose_eval=100, early_stopping_rounds = 1000, evals_result = evals_result)\noof = clf.predict(X_test, num_iteration=clf.best_iteration)\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Prediction\npredictions = clf.predict(df_test_fe[features], num_iteration=clf.best_iteration)\n\n# Visualize Metrics\naxL = lgb.plot_metric(evals_result, metric='auc')\naxL.set_title('AUC')\naxL.set_xlabel('Iterations')\naxL.set_ylim(0,1.1)\naxR = lgb.plot_metric(evals_result, metric='binary_logloss')        \naxR.set_title('Binary_Logloss')\naxR.set_xlabel('Iterations')\nplt.show()\n\n# Importance\nfold_importance_train = pd.DataFrame()\nfold_importance_train[\"feature\"] = features\nfold_importance_train[\"importance\"] = clf.feature_importance()\nfold_importance_train[\"fold\"] = 1\nfeature_importance_train = pd.concat([feature_importance_train, fold_importance_train], axis=0)\n\nprecisions, recalls, thresholds = precision_recall_curve(y_test, oof)\n\nfig = plt.figure(figsize=(14,4))\n\n### Threshold vs Precision/Recall\nax = fig.add_subplot(1,2,1)\nax.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\nax.plot(thresholds, recalls[:-1], \"g--\", label=\"Recall\")\nax.set_title(\"Threshold vs Precision/Recall\")\nax.set_xlabel(\"Threshold\")\nax.legend(loc=\"center left\")\nax.set_ylim([0,1.1])\nax.grid()\nfig.show()\n\n### Precision-Recall Curve\nax = fig.add_subplot(1,2,2)\nax.step(recalls, precisions, color='b', alpha=0.2, where='post')\nax.fill_between(recalls, precisions, step='post', alpha=0.2, color='b')\nax.set_title('Precision-Recall Curve')\nax.set_xlabel('Recall')\nax.set_ylabel('Precision')\nax.set_ylim([0.0, 1.05])\nax.set_xlim([0.0, 1.0])\nax.grid()\nfig.show()\n\ndf_train_result = pd.DataFrame()\ndf_train_result['Actual Result'] = y_test\ndf_train_result['Prediction Score'] = oof\ndf_train_result = df_train_result.sort_values('Prediction Score',ascending=False).sort_index(ascending=False)\ndf_target = df_train_result[df_train_result['Actual Result']==1]\ndf_nontarget = df_train_result[df_train_result['Actual Result']==0]\n\n### Show Importance\ncols = (feature_importance_train[[\"feature\",\"importance\"]]\n        .groupby(\"feature\")\n        .mean()\n        .sort_values(by=\"importance\", ascending=False)[:1000].index)\nbest_features = feature_importance_train.loc[feature_importance_train.feature.isin(cols)]\n\nplt.figure(figsize=(14,5))\nsns.barplot(x=\"importance\", y=\"feature\", \n            data=best_features.sort_values(by=\"importance\",ascending=False))\nplt.title('LightGBM Features (averaged over folds)')\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Interpretation by LIME","metadata":{}},{"cell_type":"code","source":"import lime\nimport lime.lime_tabular\n\ndef predict_fn(x):\n    preds = clf.predict(x, num_iteration=clf.best_iteration).reshape(-1,1)\n    p0 = 1 - preds\n    return np.hstack((p0, preds))\n\nexplainerLime = lime.lime_tabular.LimeTabularExplainer(\n    X_train.values,\n    mode='classification',\n    feature_names=features,\n   class_names=[\"NotSurvived\", \"Survived\"],\n   verbose=True\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exp = explainerLime.explain_instance(X_train[features].values[0], predict_fn, num_features=10)\nexp.show_in_notebook(show_all=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exp = explainerLime.explain_instance(X_train[features].values[1], predict_fn, num_features=10)\nexp.show_in_notebook(show_all=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exp = explainerLime.explain_instance(X_train[features].values[3], predict_fn, num_features=10)\nexp.show_in_notebook(show_all=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exp = explainerLime.explain_instance(X_train[features].values[100], predict_fn, num_features=10)\nexp.show_in_notebook(show_all=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exp = explainerLime.explain_instance(X_train[features].values[-1], predict_fn, num_features=10)\nexp.show_in_notebook(show_all=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Interpretation by SHAP","metadata":{}},{"cell_type":"code","source":"shap.initjs()\nexplainer = shap.TreeExplainer(clf)\nshap_values = explainer.shap_values(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary_plot","metadata":{}},{"cell_type":"code","source":"shap.summary_plot(shap_values, X_train)\nshap.summary_plot(shap_values, X_train, plot_type='bar')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap_values[1][0,:], X_train.iloc[0,:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap_values[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Force Plot","metadata":{}},{"cell_type":"code","source":"shap.force_plot(explainer.expected_value[1], shap_values[1][0,:], X_train.iloc[0,:])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.force_plot(explainer.expected_value[1], shap_values[1][1,:], X_train.iloc[1,:])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.force_plot(explainer.expected_value[1], shap_values[1][2,:], X_train.iloc[2,:])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.force_plot(explainer.expected_value[1], shap_values[1][3,:], X_train.iloc[3,:])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.force_plot(base_value=explainer.expected_value[1], shap_values=shap_values[1], features=X_train.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_fe.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dependency Plot","metadata":{}},{"cell_type":"code","source":"shap.dependence_plot(\"AgeBin\",shap_values[1], X_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.dependence_plot(\"Sex\",shap_values[1], X_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.dependence_plot(\"Pclass\",shap_values[1], X_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.dependence_plot(\"FareBin\",shap_values[1], X_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}